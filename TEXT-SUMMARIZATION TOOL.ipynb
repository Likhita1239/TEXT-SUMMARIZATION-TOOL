!pip install sumy
import nltk
nltk.download('punkt')  # Download required tokenizer for sumy
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer
def summarize_text(text, sentence_count=3):
    """
    Summarizes the input text using LSA summarization technique.
    
    Parameters:
    - text: String, the article to summarize
    - sentence_count: Int, number of sentences in the summary
    
    Returns:
    - summary: String, the summarized output
    """
    parser = PlaintextParser.from_string(text, Tokenizer("english"))
    summarizer = LsaSummarizer()
    summary = summarizer(parser.document, sentence_count)
    return " ".join(str(sentence) for sentence in summary)
input_text = """
Artificial intelligence (AI) is transforming industries and redefining the way we interact with technology.
From healthcare to finance, AI is being used to automate tasks, improve efficiency, and generate insights from data.
Machine learning, a subset of AI, enables systems to learn and improve from experience without being explicitly programmed.
Natural language processing (NLP), another key area, allows machines to understand and respond to human language.
As AI continues to evolve, ethical considerations and regulations are becoming increasingly important.
"""
summary = summarize_text(input_text, sentence_count=2)
print("Original Text:\n", input_text)
print("\nSummary:\n", summary)
import nltk
nltk.download('punkt')
nltk.download('punkt_tab')  # This line is essential for your error
summary = summarize_text(input_text, sentence_count=2)
print("Original Text:\n", input_text)
print("\nSummary:\n", summary)


